<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yoursite.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.12.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"show_result":true,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="《统计学习方法》（李航 第二版）的笔记 原笔记内容来自于 github项目， 我不希望在做文字笔记上花费太多的时间，而是更加注重算法本身 因此，这个篇章的学习我打算用在已有的公开笔记上做批注的形式来学习，把它当做一份教学讲义">
<meta property="og:type" content="article">
<meta property="og:title" content="第1章 统计学习及监督学习概论">
<meta property="og:url" content="http://yoursite.com/2023/07/08/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/CH01%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/index.html">
<meta property="og:site_name" content="寒木春华">
<meta property="og:description" content="《统计学习方法》（李航 第二版）的笔记 原笔记内容来自于 github项目， 我不希望在做文字笔记上花费太多的时间，而是更加注重算法本身 因此，这个篇章的学习我打算用在已有的公开笔记上做批注的形式来学习，把它当做一份教学讲义">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/images/lihang/unsupervised_learning_process.png">
<meta property="og:image" content="http://yoursite.com/.com//myblog/myblog/source/images/lihang/unsupervised_learning_process.png">
<meta property="og:image" content="http://yoursite.com/.com//myblog/myblog/source/images/lihang/reinforcement_learning_process.png">
<meta property="article:published_time" content="2023-07-08T13:18:16.000Z">
<meta property="article:modified_time" content="2023-07-12T14:48:52.007Z">
<meta property="article:author" content="树栖九天">
<meta property="article:tag" content="学习笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/lihang/unsupervised_learning_process.png">


<link rel="canonical" href="http://yoursite.com/2023/07/08/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/CH01%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://yoursite.com/2023/07/08/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/CH01%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/","path":"2023/07/08/知识库/AI/机器学习/统计学习方法/CH01统计学习及监督学习概论/","title":"第1章 统计学习及监督学习概论"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>第1章 统计学习及监督学习概论 | 寒木春华</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">寒木春华</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-links"><a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>Links</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#ch01-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA"><span class="nav-number">1.</span> <span class="nav-text">CH01 统计学习及监督学习概论</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.1.</span> <span class="nav-text">前言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AB%A0%E8%8A%82%E7%9B%AE%E5%BD%95"><span class="nav-number">1.1.1.</span> <span class="nav-text">章节目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%BC%E8%AF%BB"><span class="nav-number">1.1.2.</span> <span class="nav-text">导读</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%9A%84%E6%AD%A5%E9%AA%A4"><span class="nav-number">1.2.</span> <span class="nav-text">实现统计学习方法的步骤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%88%86%E7%B1%BB"><span class="nav-number">1.3.</span> <span class="nav-text">统计学习分类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%88%86%E7%B1%BB"><span class="nav-number">1.3.1.</span> <span class="nav-text">基本分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">监督学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">无监督学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.3.1.3.</span> <span class="nav-text">强化学习</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%89%E6%A8%A1%E5%9E%8B%E5%88%86%E7%B1%BB"><span class="nav-number">1.3.2.</span> <span class="nav-text">按模型分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%9D%9E%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">概率模型与非概率模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">线性模型和非线性模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%9D%9E%E5%8F%82%E6%95%B0%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.3.2.3.</span> <span class="nav-text">参数化模型和非参数化模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%89%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB"><span class="nav-number">1.3.3.</span> <span class="nav-text">按算法分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%89%E6%8A%80%E5%B7%A7%E5%88%86%E7%B1%BB"><span class="nav-number">1.3.4.</span> <span class="nav-text">按技巧分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.3.4.1.</span> <span class="nav-text">贝叶斯学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A0%B8%E6%96%B9%E6%B3%95"><span class="nav-number">1.3.4.2.</span> <span class="nav-text">核方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E4%B8%89%E8%A6%81%E7%B4%A0"><span class="nav-number">1.4.</span> <span class="nav-text">统计学习方法三要素</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.4.1.</span> <span class="nav-text">模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">模型是什么?</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AD%96%E7%95%A5"><span class="nav-number">1.4.2.</span> <span class="nav-text">策略</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E9%A3%8E%E9%99%A9%E5%87%BD%E6%95%B0"><span class="nav-number">1.4.2.1.</span> <span class="nav-text">损失函数与风险函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">1.4.2.2.</span> <span class="nav-text">常用损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#erm%E4%B8%8Esrm"><span class="nav-number">1.4.2.3.</span> <span class="nav-text">ERM与SRM</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E6%B3%95"><span class="nav-number">1.4.3.</span> <span class="nav-text">算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="nav-number">1.5.</span> <span class="nav-text">模型评估与模型选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="nav-number">1.5.1.</span> <span class="nav-text">过拟合与模型选择</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E4%B8%8E%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">1.6.</span> <span class="nav-text">正则化与交叉验证</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">1.6.0.1.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-number">1.6.0.2.</span> <span class="nav-text">交叉验证</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B"><span class="nav-number">1.7.</span> <span class="nav-text">泛化能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.8.</span> <span class="nav-text">生成模型与判别模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E6%96%B9%E6%B3%95"><span class="nav-number">1.8.1.</span> <span class="nav-text">生成方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A4%E5%88%AB%E6%96%B9%E6%B3%95"><span class="nav-number">1.8.2.</span> <span class="nav-text">判别方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E6%A0%87%E6%B3%A8%E9%97%AE%E9%A2%98%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98"><span class="nav-number">1.9.</span> <span class="nav-text">分类问题、标注问题、回归问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">1.10.</span> <span class="nav-text">参考</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="树栖九天"
      src="/images/my_avatar.png">
  <p class="site-author-name" itemprop="name">树栖九天</p>
  <div class="site-description" itemprop="description">欢迎，这是一个废柴大学生的博客─=≡Σ(((つ•̀ω•́)つ</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">51</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      推荐链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://jinx0106.github.io/" title="https:&#x2F;&#x2F;jinx0106.github.io&#x2F;" rel="noopener" target="_blank">思想楼阁-徐瑾</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/07/08/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/CH01%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_avatar.png">
      <meta itemprop="name" content="树栖九天">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="寒木春华">
      <meta itemprop="description" content="欢迎，这是一个废柴大学生的博客─=≡Σ(((つ•̀ω•́)つ">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="第1章 统计学习及监督学习概论 | 寒木春华">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第1章 统计学习及监督学习概论
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-07-08 21:18:16" itemprop="dateCreated datePublished" datetime="2023-07-08T21:18:16+08:00">2023-07-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-07-12 22:48:52" itemprop="dateModified" datetime="2023-07-12T22:48:52+08:00">2023-07-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%9F%A5%E8%AF%86%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">知识库</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>《统计学习方法》（李航 第二版）的笔记</p>
<p>原笔记内容来自于 <a target="_blank" rel="noopener" href="https://github.com/SmirkCao/Lihang.git">github项目</a>，
我不希望在做文字笔记上花费太多的时间，而是更加注重算法本身</p>
<p>因此，这个篇章的学习我打算用在已有的公开笔记上做批注的形式来学习，把它当做一份教学讲义</p>
<span id="more"></span>
<h1 id="ch01-统计学习及监督学习概论">CH01 统计学习及监督学习概论</h1>
<figure>
<embed src="https://www.smirkcao.info/hit_gits/Lihang/CH01/README.md">
<figcaption aria-hidden="true">Hits</figcaption>
</figure>
<p>[TOC]</p>
<h2 id="前言">前言</h2>
<h3 id="章节目录">章节目录</h3>
<ol type="1">
<li>统计学习</li>
<li>统计学习的分类
<ol type="1">
<li>基本分类</li>
<li>按模型分类</li>
<li>按算法分类</li>
<li>按技巧分类</li>
</ol></li>
<li>统计学习三要素
<ol type="1">
<li>模型</li>
<li>策略</li>
<li>算法</li>
</ol></li>
<li>模型评估与模型选择
<ol type="1">
<li>训练误差与测试误差</li>
<li>过拟合与模型选择</li>
</ol></li>
<li>正则化与交叉验证
<ol type="1">
<li>正则化</li>
<li>交叉验证</li>
</ol></li>
<li>泛化能力
<ol type="1">
<li>泛化误差</li>
<li>泛化误差上界</li>
</ol></li>
<li>生成模型与判别模型</li>
<li>监督学习应用
<ol type="1">
<li>分类问题</li>
<li>标注问题</li>
<li>回归问题</li>
</ol></li>
</ol>
<h3 id="导读">导读</h3>
<ul>
<li><p><del>直接看目录结构，会感觉有点乱，就层级结构来讲感觉并不整齐。</del>第二版重新梳理了这部分目录结构，舒服多了，尤其之前的分类，回归与标注因为出现了1.10造成目录中这部分不对齐，非常不爽。结果，第二版改了。赞</p></li>
<li><p>本章最后的三个部分，这三个问题可以对比着看，如果暂时没有概念，略过也可以，回头对各个算法有了感觉回头再看这里。
这三部分怎么对比，三部分都有个图来说明，仔细看下差异，本文后面会对此展开。</p></li>
<li><p>关于损失函数，风险函数与目标函数注意体会差异</p></li>
<li><p>后面插点从深度学习角度拿到的点</p>
<ul>
<li>关于机器学习三要素, 复旦大学邱锡鹏教授也有解读[^2]: 模型, 学习准则,
优化算法. 这个定义比较接近代码. 以Tensorflow为例.
通常会定义一个网络(模型), 定义Loss(学习准则), 定义优化算法(Optimizer),
然后开Session, 不停的把数据带入用Opitmizer去最小化Loss.</li>
<li>Losses, Metrics, 在Keras里面划分了两个模块,
解释是Losses是BP过程用到的, 而Metrics实际和损失函数类似,
用来评价模型的性能, 但是不参与反向传播. 从源码也能看到,
Metrics里面import了很多Loss算法</li>
</ul></li>
<li><p>书中例子1.1可以参考PRML中对应的表述， 更详细些。</p></li>
<li><p>在监督学习中输入和输出对称为<strong>样本</strong>，在无监督学习中输入是<strong>样本</strong>。</p></li>
<li><p>注意在介绍输入空间，输出空间等概念的时候，以及这一章的很多部分都会有个帽子，<code>监督学习中</code>，
书中也明确了<code>本书主要讨论监督学习的问题</code>，最后的概要总结部分对监督学习有这样的描述：<code>监督学习可以概括如下：从给定有限的训练数据出发，假设数据是独立同分布的，而且假设模型属于某个假设空间，应用某一评价准则，从假设空间中选取一个最优的模型，使它对已给的训练数据以及未知测试数据在给定评价标准意义下有最准确的预测。</code>，理解下这里的假设。</p></li>
<li><p>在贝叶斯学习部分，提到<code>将模型、为观测要素及其参数用变量表示，使用模型的先验分布是贝叶斯学习的特点。</code>注意这里面先验是<strong>模型</strong>的先验分布。</p></li>
<li><p>在泛化误差部分，用了<span class="math inline">\(\hat
f\)</span>表示最优估计，这个有时候也会用<span class="math inline">\(f^*\)</span>表示意思差不多。有时候表示向量又要表示估计值，用<span class="math inline">\(*\)</span>可能好看一点，比如<span class="math inline">\(\vec
x^*\)</span>，但是通常没本书都有自己的符号体系，向量可以通过字体表示，具体可以从书中的符号表部分了解。关于这一点，在第二版第一章就有所体现，监督和无监督学习中，模型用hat表示，在强化学习中，最优解用*表示。</p></li>
<li><p>提一下参考文献，几个大部头都在，ESL，PRML，DL，PGM，西瓜书，还有Sutton的强化学习，不过这本书2018年出了第二版，感兴趣的话可以看新版。</p></li>
</ul>
<h2 id="实现统计学习方法的步骤">实现统计学习方法的步骤</h2>
<p>统计学习方法三要素：模型，策略，算法</p>
<blockquote>
<ol type="1">
<li>得到一个有限的训练数据集合</li>
<li>确定包含所有可能的模型的<strong>假设空间</strong>，即学习模型的集合</li>
<li>确定模型选择的准则，即学习的<strong>策略</strong></li>
<li>实现求解最优模型的算法，即学习的<strong>算法</strong></li>
<li>通过学习方法选择最优的模型</li>
<li>利用学习的最优模型对新数据进行预测或分析</li>
</ol>
</blockquote>
<h2 id="统计学习分类">统计学习分类</h2>
<h3 id="基本分类">基本分类</h3>
<p>这部分内容新增了无监督学习和强化学习。值得注意的一个点，之前因为只写了监督学习，样本表示(x,
y)对，在无监督学习里面，样本就是x。</p>
<h4 id="监督学习">监督学习</h4>
<blockquote>
<p>my note:</p>
<blockquote>
<ol type="1">
<li><strong>输入变量</strong>和<strong>输出变量</strong>均为<strong>连续变量的预测问题</strong>称为<strong>回归问题</strong></li>
<li>输出变量为有限个离散变量的预测问题称为分类问题</li>
<li>输入变量与输出变量均为变量序列的预测问题称为标注问题（比如文本词性分析序列）</li>
</ol>
</blockquote>
</blockquote>
<h4 id="无监督学习">无监督学习</h4>
<blockquote>
<p>my note:</p>
<blockquote>
<p>学习数据中的统计规律或者潜在结构</p>
<p>流程和监督学习类似，如下图</p>
</blockquote>
</blockquote>
<p>引文本地预览和渲染的路径问题，以后的图片都会放两张，所以必然会有一个失效图链接</p>
<figure>
<img src="/images/lihang/unsupervised_learning_process.png" alt="无监督学习流程">
<figcaption aria-hidden="true">无监督学习流程</figcaption>
</figure>
<figure>
<img src="/.com//myblog\myblog\source\images\lihang\unsupervised_learning_process.png" alt="无监督学习流程">
<figcaption aria-hidden="true">无监督学习流程</figcaption>
</figure>
<h4 id="强化学习">强化学习</h4>
<figure>
<img src="/.com//myblog\myblog\source\images\lihang\reinforcement_learning_process.png" alt="强化学习方法流程">
<figcaption aria-hidden="true">强化学习方法流程</figcaption>
</figure>
<blockquote>
<p>my note:</p>
<blockquote>
<p>s 代表 state</p>
<p>a 表示 action</p>
<p>r 表示 reward</p>
<p>上述是强化学习的马尔可夫决策过程的模型，是三者的序列的随机过程，由五元组$S,A,P,r,$构成</p>
<p>细节请查书</p>
</blockquote>
<blockquote>
<p>有模型的方法，可以直接通过求价值函数<span class="math display">\[v_{\pi}(s) \]</span>的最大值得到最佳策略</p>
<p>无模型、基于策略的方法，则是求解最优策略，通常从一个策略开始，搜索更加优秀的策略进行</p>
<p>无模型、基于价值的方法，通过求解最优价值函数，特别是最优动作价值函数来间接得到策略</p>
</blockquote>
</blockquote>
<h3 id="按模型分类">按模型分类</h3>
<h4 id="概率模型与非概率模型">概率模型与非概率模型</h4>
<p>在监督学习中，概率模型是生成模型，非概率模型是判别模型。</p>
<h4 id="线性模型和非线性模型">线性模型和非线性模型</h4>
<blockquote>
<p>my note:</p>
<blockquote>
<p>函数为线性函数的模型即为线性模型，反之为非线性模型</p>
</blockquote>
</blockquote>
<h4 id="参数化模型和非参数化模型">参数化模型和非参数化模型</h4>
<blockquote>
<p>my note: &gt; 参数维度确定，不会变化的为参数化模型</p>
<blockquote>
<p>参数维度会变化或者无穷大则为非参数化模型</p>
</blockquote>
</blockquote>
<h3 id="按算法分类">按算法分类</h3>
<p>在线学习和批量学习，在线学习通常比批量学习更难。</p>
<blockquote>
<p>my note:</p>
<blockquote>
<p>一口吃一个消化完再吃，一口全吃了再消化的区别</p>
</blockquote>
</blockquote>
<h3 id="按技巧分类">按技巧分类</h3>
<h4 id="贝叶斯学习">贝叶斯学习</h4>
<blockquote>
<p>根据贝叶斯定理，得到计算后验概率的公式</p>
<p><span class="math display">\[
(\theta|D)={\frac{P(\theta)P(D|\theta)}{P(D)}}
\]</span></p>
</blockquote>
<blockquote>
<p>通常使用后验概率达到最大的模型</p>
<p>还有一个最大似然估计，书本上的内容太模糊，没看懂</p>
</blockquote>
<h4 id="核方法">核方法</h4>
<h2 id="统计学习方法三要素">统计学习方法三要素</h2>
<h3 id="模型">模型</h3>
<h4 id="模型是什么">模型是什么?</h4>
<p>在监督学习过程中，模型就是所要学习的<strong>条件概率分布</strong>或者<strong>决策函数</strong>。</p>
<p>注意书中的这部分描述，整理了一下到表格里：</p>
<table>
<colgroup>
<col style="width: 10%">
<col style="width: 51%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>假设空间<span class="math inline">\(\cal F\)</span></th>
<th>输入空间<span class="math inline">\(\cal X\)</span></th>
<th>输出空间<span class="math inline">\(\cal Y\)</span></th>
<th>参数空间</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>决策函数</td>
<td><span class="math inline">\(\cal F\it =\{f_{\theta}
|Y=f_{\theta}(x), \theta \in \bf R \it ^n\}\)</span></td>
<td>变量</td>
<td>变量</td>
<td><span class="math inline">\(\bf R\it ^n\)</span></td>
</tr>
<tr class="even">
<td>条件概率分布</td>
<td><span class="math inline">\(\cal F\it =\{P|P_{\theta}(Y|X),\theta\in
\bf R \it ^n\}\)</span></td>
<td>随机变量</td>
<td>随机变量</td>
<td><span class="math inline">\(\bf R\it ^n\)</span></td>
</tr>
</tbody>
</table>
<p>书中描述的时候，有提到<strong>条件概率分布族</strong>，这个留一下，后面<a href="../CH06/README.md">CH06</a>有提到确认逻辑斯谛分布属于指数分布族。</p>
<h3 id="策略">策略</h3>
<h4 id="损失函数与风险函数">损失函数与风险函数</h4>
<blockquote>
<p><strong>损失函数</strong>度量模型<strong>一次预测</strong>的好坏，<strong>风险函数</strong>度量<strong>平均意义</strong>下模型预测的好坏。</p>
</blockquote>
<ol type="1">
<li><p>损失函数(loss function)或代价函数(cost function)
损失函数定义为给定输入<span class="math inline">\(X\)</span>的<strong>预测值<span class="math inline">\(f(X)\)</span></strong>和<strong>真实值<span class="math inline">\(Y\)</span></strong>之间的<strong>非负实值</strong>函数，记作<span class="math inline">\(L(Y,f(X))\)</span></p></li>
<li><p><strong>风险函数</strong>(risk
function)或<strong>期望损失</strong>(expected loss)
这个和模型的泛化误差的形式是一样的 $ R_{exp}(f)=E_p[L(Y,
f(X))]=_{XY}L(y,f(x))P(x,y), {}x{}y $ 模型<span class="math inline">\(f(X)\)</span>关于联合分布<span class="math inline">\(P(X,Y)\)</span>的<strong>平均意义下的</strong>损失(<strong>期望</strong>损失)，但是因为<span class="math inline">\(P(X,Y)\)</span>是未知的，所以前面的用词是<strong>期望</strong>，以及<strong>平均意义下的</strong>。</p>
<p>这个表示其实就是损失的均值，反映了对整个数据的预测效果的好坏，P(x,y)转换成<span class="math inline">\(\frac {\nu(X=x, Y=y)}{N}\)</span>更容易直观理解,
可以参考<a href="../CH09/README.md">CH09</a>，6.2.2节的部分描述来理解，但是真实的数据N是无穷的。</p></li>
<li><p><strong>经验风险</strong>(empirical
risk)或<strong>经验损失</strong>(empirical loss) <span class="math inline">\(R_{emp}(f)=\frac{1}{N}\sum^{N}_{i=1}L(y_i,f(x_i))\)</span>
模型<span class="math inline">\(f\)</span>关于<strong>训练样本集</strong>的平均损失
<strong>根据大数定律，当样本容量N趋于无穷大时，经验风险趋于期望风险</strong></p></li>
<li><p><strong>结构风险</strong>(structural risk) <span class="math inline">\(R_{srm}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))+\lambda
J(f)\)</span> <span class="math inline">\(J(f)\)</span>为模型复杂度,
<span class="math inline">\(\lambda \geqslant
0\)</span>是系数，用以权衡经验风险和模型复杂度。</p></li>
</ol>
<blockquote>
<p><strong>结构风险的最小化就是正则化</strong>，目的是防止过拟合，这是因为数据量可能不足</p>
<p>通常模型 <span class="math inline">\(f\)</span> 越复杂，<span class="math inline">\(J(f)\)</span> 作为模型的复杂度，也就越复杂</p>
<p><span class="math inline">\(\lambda\)</span>表示的是对经验风险和模型复杂度的权衡</p>
<p>所以，求解最优模型就是对下列问题进行最优化求解： <span class="math display">\[
\operatorname*{min}_{f\in{\cal
F}}\frac{1}{N}\sum_{i=1}^{N}L(y_{i},f(x_{i}))+\lambda J(f)
\]</span></p>
</blockquote>
<h4 id="常用损失函数">常用损失函数</h4>
<p>损失函数数值越小，模型就越好</p>
<ol type="1">
<li><p>0-1损失 <span class="math inline">\(L(Y,f(X))=\begin{cases}1, Y
\neq f(X) \\0, Y=f(X) \end{cases}\)</span></p></li>
<li><p>平方损失 <span class="math inline">\(L(Y,f(X))=(Y-f(X))^2\)</span></p></li>
<li><p>绝对损失 <span class="math inline">\(L(Y,f(X))=|Y-f(X)|\)</span></p></li>
<li><p>对数损失 这里<span class="math inline">\(P(Y|X)\leqslant
1\)</span>，对应的对数是负值，所以对数损失中包含一个负号，为什么不是绝对值？因为肯定是负的。
<span class="math inline">\(L(Y,P(Y|X))=-\log P(Y|X)\)</span></p></li>
</ol>
<h4 id="erm与srm">ERM与SRM</h4>
<p>经验风险最小化(ERM)与结构风险最小化(SRM)</p>
<ol type="1">
<li><strong>极大似然估计</strong>是经验风险最小化的一个例子
当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化等价于极大似然估计</li>
<li><strong>贝叶斯估计</strong>中的<strong>最大后验概率估计</strong>是结构风险最小化的一个例子
当模型是条件概率分布，损失函数是对数损失函数，<strong>模型复杂度由模型的先验概率表示</strong>时，结构风险最小化等价于最大后验概率估计</li>
</ol>
<h3 id="算法">算法</h3>
<p>这章里面简单提了一下，具体可以参考<a href="../CH12/README.md">CH12</a>表格中关于学习算法的描述。</p>
<h2 id="模型评估与模型选择">模型评估与模型选择</h2>
<p>训练误差和测试误差是模型关于数据集的平均损失。</p>
<p>提到一句，
<code>统计学习方法具体采用的损失函数未必是评估时使用的损失函数</code>，这句理解下。参考下在数据科学比赛中给出的评分标准，与实际学习采用的损失函数之间的关系。</p>
<h3 id="过拟合与模型选择">过拟合与模型选择</h3>
<p>这部分讲到了最小二乘法，给了PRML中的一个例子。</p>
<p>这个问题中<strong>训练数据</strong>为<span class="math inline">\(T=\{(x_1,
y_1),(x_2,y_2),\cdots,(x_N,y_N)\}\)</span></p>
<p><strong>模型</strong>为</p>
<p><span class="math inline">\(f_M(x,w)=w_0+w_1x+w_2x^2+\cdots+w_Mx^M=\sum\limits_{j=0}^Mw_jx^j\)</span></p>
<p>经验风险最小化策略下</p>
<p><span class="math inline">\(L(w)=\frac{1}{2}\sum\limits_{i=1}^N(f(x_i,w)-y_i)^2\)</span></p>
<p>将模型和训练数据带入到上式得到</p>
<p><span class="math inline">\(L(w)=\frac{1}{2}\sum\limits_{i=1}^N\left(\sum\limits_{j=0}^Mw_jx_i^j-y_i\right)^2=\frac{1}{2}\sum\limits_{i=1}^N(w\cdot
x_i-y_i)^2\)</span></p>
<p>这个问题要求<span class="math inline">\(w=(w_0^*,w_1^*,\cdots,w_M^*)\)</span></p>
<p>对<span class="math inline">\(w\)</span>求偏导令其为零，得到一系列方程，求解可以用梯度下降或者矩阵分解。</p>
<p>求解线性方程组<span class="math inline">\(Ax=b\)</span>，可以表示为<span class="math inline">\(x=A/b\)</span>，问题展开之后可以涉及到<strong>矩阵分解</strong>。</p>
<p>TODO: 这个例子展开一下</p>
<h2 id="正则化与交叉验证">正则化与交叉验证</h2>
<h4 id="正则化">正则化</h4>
<p>模型选择的典型方法是正则化</p>
<blockquote>
<p>my note:</p>
<blockquote>
<p>正则化是结构风险最小化策略的实现</p>
</blockquote>
</blockquote>
<h4 id="交叉验证">交叉验证</h4>
<p>另一种常用的模型选择方法是交叉验证</p>
<ul>
<li>简单</li>
<li>S折(K折, K-Fold)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
<li>留一法</li>
</ul>
<p>关于交叉验证，这里补充一点。</p>
<p>数据集的划分这个问题，书中有提到数据充足的情况下，将数据划分为三个部分，训练集，验证集和测试集。看到这里，不知道大家会不会有一样的问题：<strong>验证集和测试集有什么区别？</strong></p>
<p>注意这里，在算法学习的过程中，测试集可能是固定的，但是验证集和训练集可能是变化的。比如K折交叉验证的情况下，分成K折之后，其中的K-1折作为训练集，1折作为验证集，这样针对每一个模型操作K次，计算平均测试误差，最后选择平均测试误差最小的模型。这个过程中用来验证模型效果的那一折数据就是<strong>验证集</strong>。交叉<strong>验证</strong>，就是这样一个使用<strong>验证</strong>集测试模型好坏的过程。他允许我们在模型选择的过程中，使用一部分数据（验证集）“偷窥”一下模型的效果。</p>
<h2 id="泛化能力">泛化能力</h2>
<ul>
<li><p>现实中采用最多的方法是通过测试误差来评价学习方法的泛化能力</p></li>
<li><p>统计学习理论试图从理论上对学习方法的泛化能力进行分析</p></li>
<li><p>学习方法的泛化能力往往是通过研究泛化误差的<strong>概率上界</strong>进行的,
简称为泛化误差上界(generalization error bound)</p>
<p>这本书里面讨论的不多，在<a href="../CH08/README.md">CH08</a>里面有讨论提升方法的误差分析, 提到<span class="math inline">\(AdaBoost\)</span>不需要知道下界<span class="math inline">\(\gamma\)</span>。在<a href="../CH02/README.md">CH02</a>中讨论算法的收敛性的时候有提到误分类次数的上界.</p></li>
</ul>
<p>注意泛化误差的定义，书中有说<strong>事实上，泛化误差就是所学习到的模型的期望风险</strong></p>
<h2 id="生成模型与判别模型">生成模型与判别模型</h2>
<p><strong>监督学习方法</strong>可分为<strong>生成方法</strong>(generative
approach)与<strong>判别方法</strong>(discriminative approach)</p>
<h3 id="生成方法">生成方法</h3>
<p>generative approach</p>
<ul>
<li>可以还原出<strong>联合概率分布</strong><span class="math inline">\(P(X,Y)\)</span></li>
<li>收敛速度快, 当样本容量增加时, 学到的模型可以更快收敛到真实模型</li>
<li>当存在隐变量时仍可以用</li>
</ul>
<h3 id="判别方法">判别方法</h3>
<p>discriminative approach</p>
<ul>
<li>直接学习<strong>条件概率</strong><span class="math inline">\(P(Y|X)\)</span>或者<strong>决策函数</strong><span class="math inline">\(f(X)\)</span></li>
<li>直接面对预测, 往往学习准确率更高</li>
<li>可以对数据进行各种程度的抽象, 定义特征并使用特征,
可以简化学习问题</li>
</ul>
<h2 id="分类问题标注问题回归问题">分类问题、标注问题、回归问题</h2>
<p>Classification, Tagging, Regression</p>
<ul>
<li>图1.4和图1.5除了分类系统和标注系统的差异外，没看到其他差异，但实际上这两幅图中对应的输入数据有差异，序列数据的<span class="math inline">\(x_i =
(x_i^{(1)},x_i^{(2)},\dots,x_i^{(n)})^T\)</span>对应了</li>
<li>图1.5和图1.6，回归问题的产出为<span class="math inline">\(Y=\hat
f(X)\)</span></li>
</ul>
<h2 id="参考">参考</h2>
<p>参考文献都是大部头，ESL，PRML在列</p>
<ol type="1">
<li></li>
<li>[^2 ]: <a target="_blank" rel="noopener" href="https://github.com/nndl/nndl.github.io/blob/master/chap-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0.pdf">NNDL</a></li>
</ol>
<p><strong><a href="#导读">⬆ top</a></strong></p>
<aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p><a href="##参考">ESL:7.10.1:K-Forld Cross
Validation</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>树栖九天
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://yoursite.com/2023/07/08/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/CH01%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/" title="第1章 统计学习及监督学习概论">http://yoursite.com/2023/07/08/知识库/AI/机器学习/统计学习方法/CH01统计学习及监督学习概论/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag"># 学习笔记</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/07/01/%E5%88%86%E4%BA%AB/%E4%B8%80%E4%B8%AA%E6%99%AE%E9%80%9A%E4%BA%BA%E3%80%90%E5%B9%B8%E8%BF%90%E3%80%91%E8%BF%90%E7%9A%84%E5%89%8D%E5%8D%8A%E7%94%9F/" rel="prev" title="一个普通人[幸运]的前半生">
                  <i class="fa fa-chevron-left"></i> 一个普通人[幸运]的前半生
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/07/12/%E7%9F%A5%E8%AF%86%E5%BA%93/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/CH02%E6%84%9F%E7%9F%A5%E6%9C%BA/" rel="next" title="第2章 感知机">
                  第2章 感知机 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2022 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">树栖九天</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">91k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">1:22</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <script size="200" alpha="0.2" zIndex="1" src="https://cdnjs.cloudflare.com/ajax/libs/ribbon.js/1.0.2/ribbon.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.1/es5/tex-mml-chtml.js","integrity":"sha256-hlC2uSQYTmPsrzGZTEQEg9PZ1a/+SV6VBCTclohf2og="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
